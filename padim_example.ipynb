{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnomaVision Pipeline\n",
    "Complete workflow: Train → Export → Detect → Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import anomavision\n",
    "from anomavision.config import load_config\n",
    "from anomavision.general import Profiler, determine_device, increment_path\n",
    "from anomavision.inference.model.wrapper import ModelWrapper\n",
    "from anomavision.inference.modelType import ModelType\n",
    "from anomavision.utils import (\n",
    "    adaptive_gaussian_blur,\n",
    "    get_logger,\n",
    "    setup_logging,\n",
    "    save_args_to_yaml\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = edict(load_config(\"config.yml\"))\n",
    "\n",
    "# Setup logging\n",
    "setup_logging(enabled=True, log_level=config.log_level, log_to_file=True)\n",
    "logger = get_logger(\"anomavision.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset path\n",
    "root = os.path.join(\n",
    "    os.path.realpath(config.dataset_path),\n",
    "    config.class_name,\n",
    "    \"train\",\n",
    "    \"good\"\n",
    ")\n",
    "\n",
    "# Create dataset\n",
    "ds = anomavision.AnodetDataset(\n",
    "    root,\n",
    "    resize=config.resize,\n",
    "    crop_size=config.crop_size,\n",
    "    normalize=config.normalize,\n",
    "    mean=config.norm_mean,\n",
    "    std=config.norm_std,\n",
    ")\n",
    "\n",
    "dl = DataLoader(ds, batch_size=config.batch_size, shuffle=False)\n",
    "logger.info(f\"Dataset: {len(ds)} images | batch_size={config.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device and model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Device: {device.type}\")\n",
    "\n",
    "padim = anomavision.Padim(\n",
    "    backbone=config.backbone,\n",
    "    device=device,\n",
    "    layer_indices=config.layer_indices,\n",
    "    feat_dim=config.feat_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "t0 = time.perf_counter()\n",
    "padim.fit(dl)\n",
    "logger.info(f\"Training completed in {time.perf_counter() - t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "run_dir = increment_path(\n",
    "    Path(config.model_data_path) / config.run_name,\n",
    "    exist_ok=True,\n",
    "    mkdir=True\n",
    ")\n",
    "\n",
    "model_path = run_dir / config.output_model\n",
    "torch.save(padim, str(model_path))\n",
    "\n",
    "# Save compact statistics\n",
    "stats_path = model_path.with_suffix(\".pth\")\n",
    "padim.save_statistics(str(stats_path), half=True)\n",
    "\n",
    "# Save config\n",
    "save_args_to_yaml(config, str(run_dir / \"config.yml\"))\n",
    "\n",
    "logger.info(f\"Model saved: {model_path}\")\n",
    "logger.info(f\"Statistics saved: {stats_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from export import ModelExporter\n",
    "\n",
    "# Reload config from saved directory\n",
    "config = edict(load_config(str(run_dir / \"config.yml\")))\n",
    "logger = get_logger(\"anomavision.export\")\n",
    "\n",
    "# Setup paths\n",
    "model_path = run_dir / config.output_model\n",
    "model_stem = Path(config.output_model).stem\n",
    "\n",
    "# Input shape\n",
    "h, w = config.crop_size if config.crop_size else config.resize\n",
    "input_shape = (1, 3, h, w)\n",
    "\n",
    "# Calibration directory\n",
    "calib_dir = os.path.join(\n",
    "    config.dataset_path,\n",
    "    config.class_name,\n",
    "    \"train\",\n",
    "    \"good\"\n",
    ")\n",
    "\n",
    "logger.info(f\"Exporting model: {model_path}\")\n",
    "logger.info(f\"Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize exporter\n",
    "exporter = ModelExporter(model_path, run_dir, logger, device=config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX\n",
    "onnx_path = exporter.export_onnx(\n",
    "    input_shape=input_shape,\n",
    "    output_name=f\"{model_stem}.onnx\",\n",
    "    opset_version=config.opset,\n",
    "    dynamic_batch=config.dynamic_batch,\n",
    "    quantize_dynamic_flag=False,\n",
    "    quantize_static_flag=False,\n",
    ")\n",
    "logger.info(f\"ONNX exported: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to TorchScript\n",
    "ts_path = exporter.export_torchscript(\n",
    "    input_shape=input_shape,\n",
    "    output_name=f\"{model_stem}.torchscript\",\n",
    "    optimize=config.optimize,\n",
    ")\n",
    "logger.info(f\"TorchScript exported: {ts_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to OpenVINO\n",
    "ov_path = exporter.export_openvino(\n",
    "    input_shape=input_shape,\n",
    "    output_name=f\"{model_stem}_openvino\",\n",
    "    fp16=not config.fp32,\n",
    "    dynamic_batch=config.dynamic_batch,\n",
    ")\n",
    "logger.info(f\"OpenVINO exported: {ov_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload config\n",
    "config = edict(load_config(str(run_dir / \"config.yml\")))\n",
    "logger = get_logger(\"anomavision.detect\")\n",
    "\n",
    "# Setup paths\n",
    "DATASET_PATH = os.path.realpath(config.img_path)\n",
    "MODEL_DATA_PATH = os.path.realpath(str(run_dir))\n",
    "device_str = determine_device(config.device)\n",
    "\n",
    "logger.info(f\"Device: {device_str}\")\n",
    "logger.info(f\"Dataset: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (using ONNX export)\n",
    "model_file = f\"{model_stem}.onnx\"\n",
    "model_path_detect = os.path.join(MODEL_DATA_PATH, model_file)\n",
    "model = ModelWrapper(model_path_detect, device_str)\n",
    "model_type = ModelType.from_extension(model_path_detect)\n",
    "\n",
    "logger.info(f\"Model loaded: {model_type.value.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "test_dataset = anomavision.AnodetDataset(\n",
    "    DATASET_PATH,\n",
    "    resize=config.resize,\n",
    "    crop_size=config.crop_size,\n",
    "    normalize=config.normalize,\n",
    "    mean=config.norm_mean,\n",
    "    std=config.norm_std,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory,\n",
    ")\n",
    "\n",
    "logger.info(f\"Dataset: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "if config.save_visualizations:\n",
    "    RESULTS_PATH = increment_path(\n",
    "        Path(config.viz_output_dir) / model_type.value.upper() / config.run_name,\n",
    "        exist_ok=config.overwrite,\n",
    "        mkdir=True,\n",
    "    )\n",
    "    logger.info(f\"Results path: {RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    first = next(iter(test_dataloader))  # (batch, images, _, _)\n",
    "    first_batch = first[0]\n",
    "    if device_str == \"cuda\":\n",
    "        first_batch = first_batch.half()\n",
    "\n",
    "    first_batch = first_batch.to(device_str)\n",
    "\n",
    "    model.warmup(batch=first_batch, runs=2)\n",
    "    logger.info(\n",
    "        \"AnomaVision warm-up done with first batch %s.\", tuple(first_batch.shape)\n",
    "    )\n",
    "except StopIteration:\n",
    "    logger.warning(\"Dataset empty; skipping warm-up.\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Warm-up skipped due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse visualization color\n",
    "viz_color = tuple(map(int, config.viz_color.split(\",\")))\n",
    "\n",
    "# Initialize profiler\n",
    "inference_profiler = Profiler()\n",
    "\n",
    "# Run inference (show first batch only)\n",
    "for batch_idx, (batch, images, _, _) in enumerate(test_dataloader):\n",
    "    if device_str == \"cuda\":\n",
    "        batch = batch.half()\n",
    "    batch = batch.to(device_str)\n",
    "\n",
    "    # Inference\n",
    "    with inference_profiler:\n",
    "        image_scores, score_maps = model.predict(batch)\n",
    "\n",
    "    # Postprocessing\n",
    "    score_maps = adaptive_gaussian_blur(score_maps, kernel_size=33, sigma=4)\n",
    "    score_map_classifications = anomavision.classification(score_maps, config.thresh)\n",
    "    image_classifications = anomavision.classification(image_scores, config.thresh)\n",
    "\n",
    "    # Visualization (only first batch)\n",
    "    if config.enable_visualization and batch_idx == 0:\n",
    "        test_images = np.array(images)\n",
    "\n",
    "        boundary_images = anomavision.visualization.framed_boundary_images(\n",
    "            test_images,\n",
    "            score_map_classifications.numpy() if hasattr(score_map_classifications, 'numpy') else score_map_classifications,\n",
    "            image_classifications.numpy() if hasattr(image_classifications, 'numpy') else image_classifications,\n",
    "            padding=config.viz_padding,\n",
    "        )\n",
    "\n",
    "        heatmap_images = anomavision.visualization.heatmap_images(\n",
    "            test_images,\n",
    "            score_maps if isinstance(score_maps, np.ndarray) else score_maps.numpy(),\n",
    "            alpha=config.viz_alpha,\n",
    "        )\n",
    "\n",
    "        highlighted_images = anomavision.visualization.highlighted_images(\n",
    "            [images[i] for i in range(len(images))],\n",
    "            score_map_classifications.numpy() if hasattr(score_map_classifications, 'numpy') else score_map_classifications,\n",
    "            color=viz_color,\n",
    "        )\n",
    "\n",
    "        # Display first image\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(16, 8))\n",
    "        fig.suptitle(\"AnomaVision Detection Results\", fontsize=14)\n",
    "\n",
    "        axs[0].imshow(images[0])\n",
    "        axs[0].set_title(\"Original\")\n",
    "        axs[0].axis(\"off\")\n",
    "\n",
    "        axs[1].imshow(boundary_images[0])\n",
    "        axs[1].set_title(\"Boundary\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "        axs[2].imshow(heatmap_images[0])\n",
    "        axs[2].set_title(\"Heatmap\")\n",
    "        axs[2].axis(\"off\")\n",
    "\n",
    "        axs[3].imshow(highlighted_images[0])\n",
    "        axs[3].set_title(\"Highlighted\")\n",
    "        axs[3].axis(\"off\")\n",
    "\n",
    "        if config.save_visualizations:\n",
    "            plt.savefig(RESULTS_PATH / f\"batch_{batch_idx}.png\", dpi=100, bbox_inches=\"tight\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "# Close model\n",
    "model.close()\n",
    "\n",
    "# Performance summary\n",
    "inference_fps = inference_profiler.get_fps(len(test_dataset))\n",
    "logger.info(f\"Inference FPS: {inference_fps:.2f}\")\n",
    "logger.info(f\"Total time: {inference_profiler.accumulated_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload config\n",
    "config = edict(load_config(str(run_dir / \"config.yml\")))\n",
    "logger = get_logger(\"anomavision.eval\")\n",
    "\n",
    "# Setup paths\n",
    "DATASET_PATH = os.path.realpath(config.dataset_path)\n",
    "MODEL_DATA_PATH = os.path.realpath(str(run_dir))\n",
    "device_str = determine_device(config.device)\n",
    "\n",
    "logger.info(f\"Device: {device_str}\")\n",
    "logger.info(f\"Dataset: {DATASET_PATH}\")\n",
    "logger.info(f\"Class: {config.class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path_eval = os.path.join(MODEL_DATA_PATH, model_file)\n",
    "model = ModelWrapper(model_path_eval, device_str)\n",
    "model_type = ModelType.from_extension(model_path_eval)\n",
    "\n",
    "logger.info(f\"Model loaded: {model_type.value.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset\n",
    "test_dataset = anomavision.MVTecDataset(\n",
    "    DATASET_PATH,\n",
    "    config.class_name,\n",
    "    is_train=False,\n",
    "    resize=config.resize,\n",
    "    crop_size=config.crop_size,\n",
    "    normalize=config.normalize,\n",
    "    mean=config.norm_mean,\n",
    "    std=config.norm_std,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory and device_str == \"cuda\",\n",
    ")\n",
    "\n",
    "logger.info(f\"Test dataset: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "all_images = []\n",
    "all_image_classifications_target = []\n",
    "all_masks_target = []\n",
    "all_image_scores = []\n",
    "all_score_maps = []\n",
    "\n",
    "evaluation_profiler = Profiler()\n",
    "\n",
    "for batch_idx, (batch, images, image_targets, mask_targets) in enumerate(test_dataloader):\n",
    "    batch = batch.to(device_str)\n",
    "\n",
    "    with evaluation_profiler:\n",
    "        image_scores, score_maps = model.predict(batch)\n",
    "\n",
    "    all_images.extend(images)\n",
    "    all_image_classifications_target.extend(\n",
    "        image_targets.numpy() if hasattr(image_targets, \"numpy\") else image_targets\n",
    "    )\n",
    "    all_masks_target.extend(\n",
    "        mask_targets.numpy() if hasattr(mask_targets, \"numpy\") else mask_targets\n",
    "    )\n",
    "\n",
    "    if isinstance(image_scores, np.ndarray):\n",
    "        all_image_scores.extend(image_scores.tolist())\n",
    "        all_score_maps.extend(score_maps)\n",
    "    else:\n",
    "        all_image_scores.extend(\n",
    "            image_scores.cpu().numpy().tolist() if hasattr(image_scores, \"cpu\") else image_scores.tolist()\n",
    "        )\n",
    "        all_score_maps.extend(\n",
    "            score_maps.cpu().numpy() if hasattr(score_maps, \"cpu\") else score_maps\n",
    "        )\n",
    "\n",
    "model.close()\n",
    "\n",
    "# Convert to arrays\n",
    "all_images = np.array(all_images)\n",
    "all_image_classifications_target = np.array(all_image_classifications_target)\n",
    "all_masks_target = np.squeeze(np.array(all_masks_target), axis=1)\n",
    "all_image_scores = np.array(all_image_scores)\n",
    "all_score_maps = np.array(all_score_maps)\n",
    "\n",
    "# Apply gaussian blur\n",
    "all_score_maps = adaptive_gaussian_blur(all_score_maps, kernel_size=33, sigma=4)\n",
    "\n",
    "logger.info(\"Evaluation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "anomavision.visualize_eval_data(\n",
    "    all_image_classifications_target,\n",
    "    all_masks_target.astype(np.uint8).flatten(),\n",
    "    all_image_scores,\n",
    "    all_score_maps.flatten(),\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "evaluation_fps = evaluation_profiler.get_fps(len(test_dataset))\n",
    "avg_time = evaluation_profiler.get_avg_time_ms(len(test_dataloader))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUATION PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Evaluation FPS: {evaluation_fps:.2f} images/sec\")\n",
    "print(f\"Average time: {avg_time:.2f} ms/batch\")\n",
    "print(f\"Total time: {evaluation_profiler.accumulated_time:.4f}s\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomavision-UokhWFqj-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
