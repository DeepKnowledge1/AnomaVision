# =========================
# Dataset / preprocessing (shared by train, detect, eval, stream)
# =========================
dataset_path: "D:/01-DATA"               # Root dataset folder (MVTec-style: contains train/test subfolders)
class_name: "bottle"                     # Class name for MVTec dataset
resize: [224, 224]                       # Resize dimensions before processing [width, height]
crop_size:                               # Final crop size [width, height]
normalize: true                          # Whether to normalize images
no_normalize: false                      # Inverse flag (used by CLI) â€“ keep in sync with "normalize"
norm_mean: [0.485, 0.456, 0.406]         # Mean values for normalization (ImageNet default)
norm_std:  [0.229, 0.224, 0.225]         # Standard deviation for normalization (ImageNet default)

# =========================
# Model / training
# =========================
backbone: "resnet18"                     # Backbone CNN architecture (resnet18 | wide_resnet50)
feat_dim: 50                             # Feature dimension size for embedding
layer_indices: [0]                       # Which backbone layers to extract features from (0,1,2,3)
model_data_path: "./distributions"  # Path to store/load model-related data
model: "padim_model.pt"                  # File name for saved model (used by detect/eval/export)
output_model: "padim_model.pt"           # File name for saving trained model (train.py expects this)
batch_size: 2                            # Training/evaluation/inference batch size
device: "auto"                           # Device to run on: "cpu", "cuda", or "auto"

# =========================
# Logging / run metadata
# =========================
log_level: "INFO"                        # Logging level: DEBUG, INFO, WARNING, ERROR
run_name: "anomav_exp"                   # Name of experiment run (used for organizing results)
detailed_timing: false                   # Enable detailed timing measurements

# =========================
# Visualization (shared by detect & eval)
# =========================
enable_visualization: true               # Enable visualization during inference/evaluation
save_visualizations: true                # Save visualization results to disk
viz_output_dir: "./visualizations/"      # Directory to save visualization results
viz_alpha: 0.5                           # Transparency factor for overlay heatmaps
viz_padding: 40                          # Padding added around visualization
viz_color: "128,0,128"                   # RGB color for visualization overlays

# =========================
# Inference (detect.py)
# =========================
img_path: "D:/01-DATA/test"  # Path to test images for inference
thresh: 13.0                            # Threshold for anomaly detection
num_workers: 1                          # Number of workers for dataloader
pin_memory: false                       # Use pinned memory for faster GPU transfers
overwrite: false                        # Overwrite existing run directory without auto-incrementing

# =========================
# Evaluation (eval.py)
# =========================
memory_efficient: true                  # Use memory efficient evaluation mode

# =========================
# Export (export.py)
# =========================
format: "all"                           # Export format: onnx, torchscript, openvino, all
opset: 17                               # ONNX opset version
dynamic_batch: true                     # Allow dynamic batch size in exported model
static_batch: false                     # Disable dynamic batch size (if true)
optimize: false                         # Enable mobile optimization for TorchScript
fp32: false                             # Export in FP32 precision (false => FP16 in OpenVINO)
output_path: null                       # Optional explicit output filename
half: false                             # Reserved (not actively used)
int8: false                             # Reserved (not actively used)

# =========================
# Streaming Configuration
# =========================
stream_mode: false                       # true = real-time streaming, false = static dataset

stream_source:
  type: "webcam"                         # webcam | video | mqtt | tcp

  # Webcam settings (type: webcam)
  camera_id: 0                           # Camera device index

  # Video file settings (type: video)
  video_path: "path/to/video.mp4"        # Path to video file
  loop: false                            # Loop video when it ends

  # MQTT settings (type: mqtt)
  broker: "localhost"                    # MQTT broker hostname/IP
  port: 1883                             # MQTT broker port
  topic: "camera/frames"                 # Topic to subscribe to
  client_id: null                        # Optional client ID
  keepalive: 60                          # Keepalive interval (seconds)
  qos: 0                                 # QoS level (0, 1, or 2)
  max_queue_size: 10                     # Max buffered frames
  read_timeout: 1.0                      # Timeout for reading frames (seconds)

  # TCP settings (type: tcp)
  host: "192.168.1.100"                  # TCP server hostname/IP
  port: 8080                             # TCP server port (matches code)
  recv_timeout: 1.0                      # Socket timeout for recv (seconds)
  header_size: 4                         # Length header size in bytes
  max_message_size: 10485760             # Max payload size (10MB)


# Streaming processing settings
stream_max_frames: null                  # Max frames to process (null = infinite)
stream_display_fps: true                 # Show FPS during streaming
stream_save_detections: true             # Save detected anomalies to disk
stream_detection_dir: "./stream_detections/"  # Directory for saved detections

